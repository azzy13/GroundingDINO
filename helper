# Quick Commands
# vanilla dino
CUDA_VISIBLE_DEVICES=0 python demo/inference_on_a_image.py \
-c groundingdino/config/GroundingDINO_SwinT_OGC.py \
-p weights/groundingdino_swint_ogc.pth \
-i /isis/home/hasana3/vlmtest/GroundingDINO/new_image.jpg \
-o "./output" \
-t "car or truck"

# detection with dino
python3 demo/inference_on_video.py \
  --video ./videos/car2.mp4 \
  --output ./outputs/annotated_car2.mp4 --fp16

# bytetrack added
python3 demo/inference.py --video ./videos/car2.mp4 --output ./outputs/annotated_car2.mp4 --fp16

# eval on coco 2017
python3 demo/test_ap_on_coco.py -c groundingdino/config/GroundingDINO_SwinB_cfg.py -p weights/groundingdino_swinb_cogcoor.pth --anno_path /isis/home/hasana3/vlmtest/GroundingDINO/dataset/coco/annotations/instances_val2017.json --image_dir /isis/home/hasana3/vlmtest/GroundingDINO/dataset/coco/val2017

# eval on kitti
python3 eval/eval.py --fp16

# eval on visdrone
python3 eval/eval_visdrone.py --fp16 --images /isis/home/hasana3/vlmtest/GroundingDINO/dataset/visdrone/VisDrone2019-MOT-val/sequences --labels /isis/home/hasana3/vlmtest/GroundingDINO/dataset/visdrone/VisDrone2019-MOT-val/annotations

# fp16 magic
âœ… Frame 8733 - Inference: 0.066s
ðŸŽ¬ Video saved to: ./output/CarHDfield.mp4
===================================
Total Frames: 8733
Total Inference Time: 571.77s
Average Inference Time per Frame: 0.0655s
Effective FPS: 15.27
Total Wall Clock Time: 835.18s
===================================

--fp16
âœ… Frame 1705 - Inference: 0.065s
ðŸŽ¬ Video saved to: ./output/airsim.mp4
===================================
Total Frames: 1705
Total Inference Time: 112.03s
Average Inference Time per Frame: 0.0657s
Effective FPS: 15.22
Total Wall Clock Time: 156.02s
===================================

--no-fp16
âœ… Frame 1705 - Inference: 0.083s
ðŸŽ¬ Video saved to: ./output/airsim.mp4
===================================
Total Frames: 1705
Total Inference Time: 140.24s
Average Inference Time per Frame: 0.0823s
Effective FPS: 12.16
Total Wall Clock Time: 174.79s
===================================

# results
# swinb on coco 2017 eval
Accumulating evaluation results...
DONE (t=10.98s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.626
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.815
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918
Final results: [0.5689566063791862, 0.7424579592071914, 0.6256690329199213, 0.40093975470857285, 0.6111063460867908, 0.7259646325014645, 0.41427950774607114, 0.7050418105018963, 0.7742221721138068, 0.6216316172058686, 0.8148647325828953, 0.9183224493376235]

# swinb on kitti 
Saved tracking results for 0020 to outputs/2025-06-30_0317/inference_results/0020.txt
      num_frames      MOTA     MOTP      IDF1  IDs
0015         376  0.372502  0.26394  0.543982   77
      num_frames      MOTA      MOTP      IDF1  IDs
0016         209  0.100594  0.320059  0.158218  209
      num_frames      MOTA      MOTP      IDF1  IDs
0018         325  0.597311  0.230367  0.785566   35
      num_frames      MOTA      MOTP      IDF1  IDs
0019        1059  0.217353  0.263309  0.262637  602
      num_frames      MOTA     MOTP      IDF1  IDs
0020         837  0.368051  0.25565  0.506222  266

Average MOTA: 0.331

# without downsampling
Saved tracking results for 0020 to outputs/2025-06-30_0327/inference_results/0020.txt
      num_frames      MOTA      MOTP      IDF1  IDs
0015         376  0.341005  0.215178  0.556634   63
      num_frames      MOTA      MOTP      IDF1  IDs
0016         209  0.152986  0.290162  0.176544  230
      num_frames      MOTA      MOTP      IDF1  IDs
0018         323  0.670205  0.148644  0.815595   37
      num_frames      MOTA      MOTP      IDF1  IDs
0019        1059  0.217478  0.267209  0.267669  542
      num_frames      MOTA      MOTP      IDF1  IDs
0020         837  0.378513  0.178109  0.521797  245

Average MOTA: 0.352